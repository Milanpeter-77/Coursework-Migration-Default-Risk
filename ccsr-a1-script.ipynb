{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d17933",
   "metadata": {},
   "source": [
    "# **Case 1 – Migration & Default Risk**\n",
    "> **Credit, Complexity and Systemic Risk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports –––––\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc72e5d",
   "metadata": {},
   "source": [
    "## **Data import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ba1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Migration & Default Assumptions –––––\n",
    "\n",
    "# Ratings\n",
    "vROWS = [\"AAA\",\"AA\",\"A\",\"BBB\",\"BB\",\"B\",\"CCC\"]\n",
    "vCOLS = [\"AAA\",\"AA\",\"A\",\"BBB\",\"BB\",\"B\",\"CCC\",\"D\"]\n",
    "\n",
    "# Migration probabilities (in %)\n",
    "mPROB = [\n",
    "    [91.115, 8.179, 0.607, 0.072, 0.024, 0.003, 0.000, 0.000],  # AAA\n",
    "    [0.844, 89.626, 8.954, 0.437, 0.064, 0.036, 0.018, 0.021],  # AA\n",
    "    [0.055, 2.595, 91.138, 5.509, 0.499, 0.107, 0.045, 0.052],  # A\n",
    "    [0.031, 0.147, 4.289, 90.584, 3.898, 0.708, 0.175, 0.168],  # BBB\n",
    "    [0.007, 0.044, 0.446, 6.741, 83.274, 7.667, 0.895, 0.926],  # BB\n",
    "    [0.008, 0.031, 0.150, 0.490, 5.373, 82.531, 7.894, 3.523],  # B\n",
    "    [0.000, 0.015, 0.023, 0.091, 0.388, 7.630, 83.035, 8.818],  # CCC\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "dfTRANSITIONS = pd.DataFrame(mPROB, index=vROWS, columns=vCOLS)\n",
    "\n",
    "# Reshape DataFrame to long format\n",
    "# dfTRANSITIONS = (\n",
    "#     dfTRANSITIONS.reset_index(names=\"FROM\")\n",
    "#       .melt(id_vars=\"FROM\", var_name=\"TO\", value_name=\"PROB\")\n",
    "# )\n",
    "\n",
    "# Convert probabilities from % to decimals\n",
    "# dfTRANSITIONS[\"PROB\"] = dfTRANSITIONS[\"PROB\"] / 100\n",
    "\n",
    "# Convert probabilities from % to decimals\n",
    "dfTRANSITIONS = dfTRANSITIONS / 100\n",
    "\n",
    "# Drop unused variables\n",
    "del vROWS, vCOLS, mPROB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf38bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bond Valuations –––––\n",
    "\n",
    "# Create DataFrame\n",
    "dfBONDVALUES = pd.DataFrame(\n",
    "    {\n",
    "        \"RATING\": [\"AAA\",\"AA\",\"A\",\"BBB\",\"BB\",\"B\",\"CCC\",\"D\"],\n",
    "        \"V0\": [99.40, 98.39, 97.22, 92.79, 90.11, 86.60, 77.16, None],\n",
    "        \"V1\": [99.50, 98.51, 97.53, 92.77, 90.48, 88.25, 77.88, 60.00],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af7608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Definitions –––––\n",
    "\n",
    "# Total Market Value in € mln\n",
    "iTOTALMV = 1500.0\n",
    "\n",
    "# Create DataFrame\n",
    "dfPORTFOLIOS = pd.DataFrame(\n",
    "    [\n",
    "        {\"Portfolio\": \"Investment Grade\", \"Rating\": \"AAA\", \"Weight\": 0.60},\n",
    "        {\"Portfolio\": \"Investment Grade\", \"Rating\": \"AA\",  \"Weight\": 0.30},\n",
    "        {\"Portfolio\": \"Investment Grade\", \"Rating\": \"BBB\", \"Weight\": 0.10},\n",
    "        {\"Portfolio\": \"Junk\", \"Rating\": \"BB\",  \"Weight\": 0.60},\n",
    "        {\"Portfolio\": \"Junk\", \"Rating\": \"B\",   \"Weight\": 0.35},\n",
    "        {\"Portfolio\": \"Junk\", \"Rating\": \"CCC\", \"Weight\": 0.05},\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b8a0a",
   "metadata": {},
   "source": [
    "## **Concentrated portfolio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a82376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings –––––\n",
    "\n",
    "# Correlations to run\n",
    "vRHO = [0.00, 0.33, 0.66, 1.00]\n",
    "\n",
    "# Monte Carlo draws\n",
    "iN = 200_000\n",
    "\n",
    "# Confidence levels for VaR/ES\n",
    "vALPHA = [0.90, 0.995]\n",
    "\n",
    "# Random seed for the main run\n",
    "iSEED = 7\n",
    "np.random.seed(iSEED)\n",
    "\n",
    "# Rating order (best to worst)\n",
    "sRATINGS_BEST = [\"AAA\", \"AA\", \"A\", \"BBB\", \"BB\", \"B\", \"CCC\", \"D\"]\n",
    "\n",
    "# For threshold construction we want worst -> best from the LEFT tail (default is far left)\n",
    "sRATINGS_WORST = [\"D\", \"CCC\", \"B\", \"BB\", \"BBB\", \"A\", \"AA\", \"AAA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fe01486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Migration Threshold Construction –––––\n",
    "\n",
    "# Build dictionary of thresholds\n",
    "dTHRESHOLDS = {}\n",
    "\n",
    "# Iterate over each starting rating\n",
    "for sFROM in dfTRANSITIONS.index:\n",
    "\n",
    "    # Take probabilities in worst to best order to build cumulative from the left tail\n",
    "    vP = dfTRANSITIONS.loc[sFROM, sRATINGS_WORST].values.astype(float)\n",
    "\n",
    "    # Cumulative probabilities from worst upward (left tail)\n",
    "    vCUM = np.cumsum(vP)\n",
    "\n",
    "    # Convert cumulative probabilities into z-thresholds\n",
    "    dCUT = {}\n",
    "\n",
    "    # Iterate over each destination rating (from worst to best)\n",
    "    for j, sTO in enumerate(sRATINGS_WORST):\n",
    "\n",
    "        # Cumulative probability for this rating\n",
    "        fC = vCUM[j]\n",
    "\n",
    "        # Numerical safety: clip to (tiny, 1-tiny) so norm.ppf doesn't explode accidentally\n",
    "        # for AAA the cumulative should be 1.0, norm.ppf(1)=+inf\n",
    "        if fC >= 1.0 - 1e-15: \n",
    "            fZ = np.inf\n",
    "        # for D the cumulative should be 0.0, norm.ppf(0)=-inf\n",
    "        elif fC <= 1e-15: \n",
    "            fZ = -np.inf\n",
    "        # for all others compute normally\n",
    "        else: \n",
    "            fZ = norm.ppf(fC)\n",
    "\n",
    "        # Store cutoff\n",
    "        dCUT[sTO] = fZ\n",
    "\n",
    "    # Store in main dictionary\n",
    "    dTHRESHOLDS[sFROM] = dCUT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98603107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required default threshold check for BBB -> D\n",
      "P(BBB -> D) = 0.001680\n",
      "Analytic z-threshold    = -2.932726\n",
      "Code z-threshold        = -2.932726\n",
      "Absolute difference     = 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Model Validation –––––\n",
    "# Required default threshold check for BBB -> D\n",
    "\n",
    "# Analytic probability from the transition matrix\n",
    "fP_BBB_D = float(dfTRANSITIONS.loc[\"BBB\", \"D\"])\n",
    "fZ_BBB_D_analytic = norm.ppf(fP_BBB_D)\n",
    "\n",
    "# Default threshold from the constructed dictionary\n",
    "fZ_BBB_D_code = dTHRESHOLDS[\"BBB\"][\"D\"]\n",
    "\n",
    "# Display results\n",
    "print(\"Required default threshold check for BBB -> D\")\n",
    "print(f\"P(BBB -> D) = {fP_BBB_D:.6f}\")\n",
    "print(f\"Analytic z-threshold    = {fZ_BBB_D_analytic:.6f}\")\n",
    "print(f\"Code z-threshold        = {fZ_BBB_D_code:.6f}\")\n",
    "print(f\"Absolute difference     = {abs(fZ_BBB_D_analytic - fZ_BBB_D_code):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc906713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concentrated issuer setup (one issuer per rating in portfolio):\n",
      "          Portfolio   R0  Weight    MV0     V0     UNITS\n",
      "0  Investment Grade  AAA    0.60  900.0  99.40  9.054326\n",
      "1  Investment Grade   AA    0.30  450.0  98.39  4.573636\n",
      "2  Investment Grade  BBB    0.10  150.0  92.79  1.616554\n",
      "3              Junk   BB    0.60  900.0  90.11  9.987793\n",
      "4              Junk    B    0.35  525.0  86.60  6.062356\n",
      "5              Junk  CCC    0.05   75.0  77.16  0.972006\n"
     ]
    }
   ],
   "source": [
    "# Portfolio Preparation and Allocation –––––\n",
    "\n",
    "# Ensure we can quickly lookup V0 and V1\n",
    "dV0 = dict(zip(dfBONDVALUES[\"RATING\"], dfBONDVALUES[\"V0\"]))\n",
    "dV1 = dict(zip(dfBONDVALUES[\"RATING\"], dfBONDVALUES[\"V1\"]))\n",
    "\n",
    "# Build a concentrated issuer list per portfolio:\n",
    "# Each row in dfISSUERS is one issuer (one per rating class in the portfolio)\n",
    "vISSUERS = []\n",
    "\n",
    "# Iterate over portfolios\n",
    "for sPORT in dfPORTFOLIOS[\"Portfolio\"].unique():\n",
    "\n",
    "    # Filter portfolio ratings\n",
    "    dfP = dfPORTFOLIOS[dfPORTFOLIOS[\"Portfolio\"] == sPORT].copy()\n",
    "\n",
    "    # Iterate over ratings in this portfolio\n",
    "    for _, r in dfP.iterrows():\n",
    "        # Fetch rating and weight\n",
    "        sR0 = r[\"Rating\"]\n",
    "        fW = float(r[\"Weight\"])\n",
    "\n",
    "        # Compute allocated market value, bond price, and units held\n",
    "        fMV0 = fW * float(iTOTALMV)\n",
    "        fV0 = float(dV0[sR0])\n",
    "        fUNITS = fMV0 / fV0\n",
    "\n",
    "        # Store issuer info\n",
    "        vISSUERS.append(\n",
    "            {\n",
    "                \"Portfolio\": sPORT,\n",
    "                \"R0\": sR0,\n",
    "                \"Weight\": fW,\n",
    "                \"MV0\": fMV0,\n",
    "                \"V0\": fV0,\n",
    "                \"UNITS\": fUNITS,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Convert to DataFrame\n",
    "dfISSUERS = pd.DataFrame(vISSUERS)\n",
    "\n",
    "# Display concentrated issuer setup\n",
    "print(\"Concentrated issuer setup (one issuer per rating in portfolio):\")\n",
    "print(dfISSUERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ab034bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dfISSUERS to LaTeX –––––\n",
    "\n",
    "with open(\"Documentation/Tables/ccsr-a1-issuers-concentrated.tex\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[ht]\\n\")\n",
    "    f.write(\"\\\\centering\\n\")\n",
    "    f.write(\"\\\\caption{Issuer Setup for Concentrated Portfolios}\\n\")\n",
    "    f.write(\"\\\\label{tab:issuers_concentrated}\\n\")\n",
    "    f.write(\"\\\\begin{tabular}{llrrrrr}\\n\")\n",
    "    f.write(\"\\\\toprule\\n\")\n",
    "    f.write(\"Portfolio & Rating & Weight & $\\\\text{MV}_{0}$ & $\\\\text{V}_{0}$ & Units \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\midrule\\n\")\n",
    "    for _, row in dfISSUERS.iterrows():\n",
    "        f.write(f\"{row['Portfolio']} & {row['R0']} & {row['Weight']:.2f} & {row['MV0']:.1f} & {row['V0']:.2f} & {row['UNITS']:.6f} \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\bottomrule\\n\")\n",
    "    f.write(\"\\\\end{tabular}\\n\")\n",
    "    f.write(\"\\\\end{table}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "027bddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concentrated — single issuer per rating\n",
      "          Portfolio   Rho  Expected Value    90% VaR   99.5% VaR      90% ES  \\\n",
      "0  Investment Grade  0.00     1499.945915   5.884884   27.130707   11.704225   \n",
      "1  Investment Grade  0.33     1499.975387   6.762133   33.794513   12.729194   \n",
      "2  Investment Grade  0.66     1499.961105   5.884884   37.496420   14.447747   \n",
      "3  Investment Grade  1.00     1499.982497  -1.421938   49.974574    0.488429   \n",
      "4              Junk  0.00     1499.541189  48.468414  290.029707  109.116237   \n",
      "5              Junk  0.33     1499.768007  48.468414  307.409178  112.317948   \n",
      "6              Junk  0.66     1500.115567  48.468414  370.275806  122.890348   \n",
      "7              Junk  1.00     1499.610142  48.468414  478.670725  147.202000   \n",
      "\n",
      "     99.5% ES  \n",
      "0   56.367254  \n",
      "1   56.421773  \n",
      "2   72.014173  \n",
      "3   85.167830  \n",
      "4  305.463794  \n",
      "5  377.010625  \n",
      "6  445.929820  \n",
      "7  478.670725  \n"
     ]
    }
   ],
   "source": [
    "# Monte Carlo Simulation –––––\n",
    "# For each portfolio and each correlation value\n",
    "\n",
    "# Store results \n",
    "vRESULTS = []\n",
    "\n",
    "# Iterate over portfolios\n",
    "for sPORT in dfISSUERS[\"Portfolio\"].unique():\n",
    "\n",
    "    # Filter portfolio issuers\n",
    "    dfP = dfISSUERS[dfISSUERS[\"Portfolio\"] == sPORT].reset_index(drop=True)\n",
    "    # Number of issuers in this portfolio (3 in this case)\n",
    "    iK = dfP.shape[0]\n",
    "\n",
    "    # Extract arrays of issuer params\n",
    "    vR0 = dfP[\"R0\"].tolist()\n",
    "    vUNITS = dfP[\"UNITS\"].values.astype(float)\n",
    "\n",
    "    # For each rho value, run MC and compute metrics\n",
    "    for fRHO in vRHO:\n",
    "\n",
    "        # Draw common factor Y for all scenarios\n",
    "        vY = np.random.normal(loc=0.0, scale=1.0, size=iN)\n",
    "\n",
    "        # Draw idiosyncratic eps for each issuer (matrix iN x iK)\n",
    "        mEPS = np.random.normal(loc=0.0, scale=1.0, size=(iN, iK))\n",
    "\n",
    "        # Build X matrix\n",
    "        # If rho=1, sqrt(1-rho)=0, so X_i = Y for everyone (perfect correlation)\n",
    "        fA = np.sqrt(fRHO)\n",
    "        fB = np.sqrt(1.0 - fRHO)\n",
    "\n",
    "        # Matrix of X values (iN x iK)\n",
    "        mX = fA * vY.reshape(-1, 1) + fB * mEPS  \n",
    "\n",
    "        # Convert each issuer column into migrated rating, then into V1\n",
    "        vV_PORT = np.zeros(iN, dtype=float)\n",
    "\n",
    "        # Iterate over issuers\n",
    "        for k in range(iK):\n",
    "\n",
    "            # Fetch initial rating and X values for this issuer\n",
    "            sR_INIT = vR0[k]\n",
    "            vX = mX[:, k]\n",
    "\n",
    "            # Fetch thresholds for this initial rating\n",
    "            dCUT = dTHRESHOLDS[sR_INIT]\n",
    "\n",
    "            # Now convert vX into V1 values using the cutoffs\n",
    "            vV1_ISS = np.empty(iN, dtype=float)\n",
    "\n",
    "            # Start with AAA by default (if above all cutoffs)\n",
    "            vV1_ISS[:] = float(dV1[\"AAA\"])\n",
    "\n",
    "            # D\n",
    "            mD = vX <= dCUT[\"D\"]\n",
    "            vV1_ISS[mD] = float(dV1[\"D\"])\n",
    "\n",
    "            # CCC (but not already D)\n",
    "            mCCC = (vX > dCUT[\"D\"]) & (vX <= dCUT[\"CCC\"])\n",
    "            vV1_ISS[mCCC] = float(dV1[\"CCC\"])\n",
    "\n",
    "            # B\n",
    "            mB = (vX > dCUT[\"CCC\"]) & (vX <= dCUT[\"B\"])\n",
    "            vV1_ISS[mB] = float(dV1[\"B\"])\n",
    "\n",
    "            # BB\n",
    "            mBB = (vX > dCUT[\"B\"]) & (vX <= dCUT[\"BB\"])\n",
    "            vV1_ISS[mBB] = float(dV1[\"BB\"])\n",
    "\n",
    "            # BBB\n",
    "            mBBB = (vX > dCUT[\"BB\"]) & (vX <= dCUT[\"BBB\"])\n",
    "            vV1_ISS[mBBB] = float(dV1[\"BBB\"])\n",
    "\n",
    "            # A\n",
    "            mA = (vX > dCUT[\"BBB\"]) & (vX <= dCUT[\"A\"])\n",
    "            vV1_ISS[mA] = float(dV1[\"A\"])\n",
    "\n",
    "            # AA\n",
    "            mAA = (vX > dCUT[\"A\"]) & (vX <= dCUT[\"AA\"])\n",
    "            vV1_ISS[mAA] = float(dV1[\"AA\"])\n",
    "\n",
    "            # Issuer value = UNITS * migrated V1\n",
    "            vV_PORT += vUNITS[k] * vV1_ISS\n",
    "\n",
    "        # Portfolio loss distribution in € mln\n",
    "        vLOSS = float(iTOTALMV) - vV_PORT\n",
    "\n",
    "        # Expected portfolio value (mean of V(t=1))\n",
    "        fEV = float(np.mean(vV_PORT))\n",
    "\n",
    "        # Compute VaR and ES at requested confidence levels\n",
    "        # VaR at alpha = quantile(alpha) of loss\n",
    "        # ES = mean(loss | loss >= VaR)\n",
    "        dMET = {\"EV\": fEV}\n",
    "\n",
    "        # Iterate over confidence levels\n",
    "        for fA in vALPHA:\n",
    "\n",
    "            # VaR = quantile of loss\n",
    "            fVaR = float(np.quantile(vLOSS, fA))\n",
    "\n",
    "            # Tail mask\n",
    "            mTAIL = vLOSS >= fVaR\n",
    "            fES = float(np.mean(vLOSS[mTAIL]))\n",
    "\n",
    "            # Store with formatted string keys\n",
    "            sA = f\"{int(round(fA*1000))/10:.1f}%\"\n",
    "            dMET[f\"VaR_{sA}\"] = fVaR\n",
    "            dMET[f\"ES_{sA}\"] = fES\n",
    "\n",
    "        # Store results for this portfolio x rho\n",
    "        vRESULTS.append(\n",
    "            {\n",
    "                \"Portfolio\": sPORT,\n",
    "                \"Rho\": fRHO,\n",
    "                \"Expected Value\": dMET[\"EV\"],\n",
    "                \"90% VaR\": dMET[\"VaR_90.0%\"],\n",
    "                \"99.5% VaR\": dMET[\"VaR_99.5%\"],\n",
    "                \"90% ES\": dMET[\"ES_90.0%\"],\n",
    "                \"99.5% ES\": dMET[\"ES_99.5%\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Final table for Question 1\n",
    "dfQ1 = pd.DataFrame(vRESULTS)\n",
    "\n",
    "# Make it look like the required output table order\n",
    "dfQ1 = dfQ1.sort_values([\"Portfolio\", \"Rho\"]).reset_index(drop=True)\n",
    "\n",
    "# Display results for Question 1\n",
    "print(\"Concentrated — single issuer per rating\")\n",
    "print(dfQ1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d70d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dfQ1 to LaTeX –––––\n",
    "\n",
    "with open(\"Documentation/Tables/ccsr-a1-results-concentrated.tex\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[ht]\\n\")\n",
    "    f.write(\"\\\\centering\\n\")\n",
    "    f.write(\"\\\\caption{Concentrated Portfolio Results}\\n\")\n",
    "    f.write(\"\\\\label{tab:results_concentrated}\\n\")\n",
    "    f.write(\"\\\\begin{tabular}{lrrrrrrr}\\n\")\n",
    "    f.write(\"\\\\toprule\\n\")\n",
    "    f.write(\"Portfolio & Rho ($\\\\rho$) & Expected Value & $\\\\text{VaR}_{0.90}$ & $\\\\text{VaR}_{0.995}$ & $\\\\text{ES}_{0.90}$ & $\\\\text{ES}_{0.995}$ \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\midrule\\n\")\n",
    "    for _, row in dfQ1.iterrows():\n",
    "        f.write(f\"{row['Portfolio']} & {row['Rho']:.2f} & {row['Expected Value']:.4f} & {row['90% VaR']:.2f} & {row['99.5% VaR']:.2f} & {row['90% ES']:.2f} & {row['99.5% ES']:.2f} \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\bottomrule\\n\")\n",
    "    f.write(\"\\\\end{tabular}\\n\")\n",
    "    f.write(\"\\\\end{table}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56e3db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence Check for Portfolio II Junk, rho=33%, 3 seeds:\n",
      "   Seed       N   Rho   99.5% VaR\n",
      "0     1  200000  0.33  300.088992\n",
      "1     2  200000  0.33  307.409178\n",
      "2     3  200000  0.33  300.088992\n",
      "Observed 99.5% VaR range across seeds (N=200,000): 7.320186 (in € mln)\n"
     ]
    }
   ],
   "source": [
    "# Convergence Check –––––\n",
    "# Required to verify convergence for Portfolio II (Junk) at rho = 33%, 3 times with different seeds\n",
    "\n",
    "# Settings for convergence check\n",
    "sPORT_CHECK = \"Junk\"\n",
    "fRHO_CHECK = 0.33\n",
    "vSEEDS = [1, 2, 3]\n",
    "\n",
    "# Store results\n",
    "vCHECK = []\n",
    "\n",
    "# Extract issuer info once\n",
    "dfPC = dfISSUERS[dfISSUERS[\"Portfolio\"] == sPORT_CHECK].reset_index(drop=True)\n",
    "iK = dfPC.shape[0]\n",
    "vR0 = dfPC[\"R0\"].tolist()\n",
    "vUNITS = dfPC[\"UNITS\"].values.astype(float)\n",
    "\n",
    "# Iterate over seeds\n",
    "for iS in vSEEDS:\n",
    "    np.random.seed(iS)\n",
    "\n",
    "    vY = np.random.normal(0.0, 1.0, iN)\n",
    "    mEPS = np.random.normal(0.0, 1.0, (iN, iK))\n",
    "\n",
    "    fA = np.sqrt(fRHO_CHECK)\n",
    "    fB = np.sqrt(1.0 - fRHO_CHECK)\n",
    "    mX = fA * vY.reshape(-1, 1) + fB * mEPS\n",
    "\n",
    "    vV_PORT = np.zeros(iN, dtype=float)\n",
    "\n",
    "    for k in range(iK):\n",
    "        sR_INIT = vR0[k]\n",
    "        vX = mX[:, k]\n",
    "        dCUT = dTHRESHOLDS[sR_INIT]\n",
    "\n",
    "        vV1_ISS = np.empty(iN, dtype=float)\n",
    "        vV1_ISS[:] = float(dV1[\"AAA\"])\n",
    "\n",
    "        mD = vX <= dCUT[\"D\"]\n",
    "        vV1_ISS[mD] = float(dV1[\"D\"])\n",
    "\n",
    "        mCCC = (vX > dCUT[\"D\"]) & (vX <= dCUT[\"CCC\"])\n",
    "        vV1_ISS[mCCC] = float(dV1[\"CCC\"])\n",
    "\n",
    "        mB = (vX > dCUT[\"CCC\"]) & (vX <= dCUT[\"B\"])\n",
    "        vV1_ISS[mB] = float(dV1[\"B\"])\n",
    "\n",
    "        mBB = (vX > dCUT[\"B\"]) & (vX <= dCUT[\"BB\"])\n",
    "        vV1_ISS[mBB] = float(dV1[\"BB\"])\n",
    "\n",
    "        mBBB = (vX > dCUT[\"BB\"]) & (vX <= dCUT[\"BBB\"])\n",
    "        vV1_ISS[mBBB] = float(dV1[\"BBB\"])\n",
    "\n",
    "        mA = (vX > dCUT[\"BBB\"]) & (vX <= dCUT[\"A\"])\n",
    "        vV1_ISS[mA] = float(dV1[\"A\"])\n",
    "\n",
    "        mAA = (vX > dCUT[\"A\"]) & (vX <= dCUT[\"AA\"])\n",
    "        vV1_ISS[mAA] = float(dV1[\"AA\"])\n",
    "\n",
    "        vV_PORT += vUNITS[k] * vV1_ISS\n",
    "\n",
    "    vLOSS = float(iTOTALMV) - vV_PORT\n",
    "    fVaR_995 = float(np.quantile(vLOSS, 0.995))\n",
    "\n",
    "    vCHECK.append({\"Seed\": iS, \"N\": iN, \"Rho\": fRHO_CHECK, \"99.5% VaR\": fVaR_995})\n",
    "\n",
    "# Create DataFrame\n",
    "dfCHECK_VaR = pd.DataFrame(vCHECK)\n",
    "\n",
    "# Display convergence check results\n",
    "print(\"Convergence Check for Portfolio II Junk, rho=33%, 3 seeds:\")\n",
    "print(dfCHECK_VaR)\n",
    "\n",
    "# Calculate range of 99.5% VaR across seeds\n",
    "fRANGE = float(dfCHECK_VaR[\"99.5% VaR\"].max() - dfCHECK_VaR[\"99.5% VaR\"].min())\n",
    "\n",
    "# Display range\n",
    "print(f\"Observed 99.5% VaR range across seeds (N={iN:,}): {fRANGE:.6f} (in € mln)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de20a50",
   "metadata": {},
   "source": [
    "## **Diversified portfolio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17ad345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issuer-Level Portfolio Setup for Diversification –––––\n",
    "\n",
    "# Number of issuers per rating class\n",
    "iN_ISSUERS_PER_RATING = 100\n",
    "\n",
    "vISSUERS = []\n",
    "\n",
    "# Iterate over portfolios\n",
    "for sPORT in dfPORTFOLIOS[\"Portfolio\"].unique():\n",
    "    dfP = dfPORTFOLIOS[dfPORTFOLIOS[\"Portfolio\"] == sPORT].copy()\n",
    "\n",
    "    # Iterate over ratings in this portfolio\n",
    "    for _, r in dfP.iterrows():\n",
    "        sR0 = r[\"Rating\"]\n",
    "        fW = float(r[\"Weight\"])\n",
    "\n",
    "        # Total market value allocated to this rating class\n",
    "        fMV0_CLASS = fW * float(iTOTALMV)\n",
    "\n",
    "        # Split equally among 100 issuers\n",
    "        fMV0_PER_ISS = fMV0_CLASS / iN_ISSUERS_PER_RATING\n",
    "\n",
    "        # Convert market value into \"bond units\" per issuer\n",
    "        fV0 = float(dV0[sR0])\n",
    "        fUNITS_PER_ISS = fMV0_PER_ISS / fV0\n",
    "\n",
    "        # Create 100 issuers for this rating class\n",
    "        for i in range(iN_ISSUERS_PER_RATING):\n",
    "            vISSUERS.append(\n",
    "                {\n",
    "                    \"Portfolio\": sPORT,\n",
    "                    \"R0\": sR0,\n",
    "                    \"Weight\": fW,\n",
    "                    \"MV0_CLASS\": fMV0_CLASS,\n",
    "                    \"MV0\": fMV0_PER_ISS,          # per-issuer invested MV\n",
    "                    \"V0\": fV0,\n",
    "                    \"UNITS\": fUNITS_PER_ISS,      # per-issuer bond units\n",
    "                    \"IssuerID\": f\"{sPORT}_{sR0}_{i+1:03d}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "dfISSUERS_100 = pd.DataFrame(vISSUERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9bd01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversified — 100 issuers per rating:\n",
      "          Portfolio   Rho  Expected Value    90% VaR   99.5% VaR      90% ES  \\\n",
      "0  Investment Grade  0.00     1499.961690   0.803920    2.194930    1.276378   \n",
      "1  Investment Grade  0.33     1499.956604   3.217612   16.966627    7.346806   \n",
      "2  Investment Grade  0.66     1499.956092   3.583234   31.346841   11.493582   \n",
      "3  Investment Grade  1.00     1500.003706  -1.421938   49.974574    0.466691   \n",
      "4              Junk  0.00     1499.927030   6.517068   14.295953    9.268482   \n",
      "5              Junk  0.33     1499.919128  32.643769  137.514946   65.547506   \n",
      "6              Junk  0.66     1499.920062  38.665552  265.980201  108.161632   \n",
      "7              Junk  1.00     1500.098271  48.468414  478.670725  144.705701   \n",
      "\n",
      "     99.5% ES  \n",
      "0    2.588288  \n",
      "1   24.555555  \n",
      "2   52.719401  \n",
      "3   84.100197  \n",
      "4   16.315566  \n",
      "5  172.636312  \n",
      "6  325.429728  \n",
      "7  478.670725  \n"
     ]
    }
   ],
   "source": [
    "# Monte Carlo Simulation for Diversified Portfolios –––––\n",
    "# Similar to before but now with 300 issuers per portfolio\n",
    "\n",
    "# Store results\n",
    "vRESULTS = []\n",
    "\n",
    "# Iterate over portfolios\n",
    "for sPORT in dfISSUERS_100[\"Portfolio\"].unique():\n",
    "    dfP = dfISSUERS_100[dfISSUERS_100[\"Portfolio\"] == sPORT].reset_index(drop=True)\n",
    "\n",
    "    iK = dfP.shape[0]\n",
    "    vR0 = dfP[\"R0\"].tolist()\n",
    "    vUNITS = dfP[\"UNITS\"].values.astype(float)\n",
    "\n",
    "    # For each rho value, run MC and compute metrics\n",
    "    for fRHO in vRHO:\n",
    "        # Draw one systematic factor per scenario\n",
    "        vY = np.random.normal(0.0, 1.0, iN)\n",
    "\n",
    "        # Draw idiosyncratic shocks for each issuer (now many more columns)\n",
    "        mEPS = np.random.normal(0.0, 1.0, (iN, iK))\n",
    "\n",
    "        # Build asset returns matrix\n",
    "        fA = np.sqrt(fRHO)\n",
    "        fB = np.sqrt(1.0 - fRHO)\n",
    "        mX = fA * vY.reshape(-1, 1) + fB * mEPS\n",
    "\n",
    "        # Accumulate portfolio value scenario-by-scenario\n",
    "        vV_PORT = np.zeros(iN, dtype=float)\n",
    "\n",
    "        # Loop over issuers (same logic as Q1, just more issuers)\n",
    "        for k in range(iK):\n",
    "            sR_INIT = vR0[k]\n",
    "            vX = mX[:, k]\n",
    "            dCUT = dTHRESHOLDS[sR_INIT]\n",
    "\n",
    "            # Assign migrated V1 per scenario using threshold intervals\n",
    "            vV1_ISS = np.empty(iN, dtype=float)\n",
    "            vV1_ISS[:] = float(dV1[\"AAA\"])\n",
    "\n",
    "            mD = vX <= dCUT[\"D\"]\n",
    "            vV1_ISS[mD] = float(dV1[\"D\"])\n",
    "\n",
    "            mCCC = (vX > dCUT[\"D\"]) & (vX <= dCUT[\"CCC\"])\n",
    "            vV1_ISS[mCCC] = float(dV1[\"CCC\"])\n",
    "\n",
    "            mB = (vX > dCUT[\"CCC\"]) & (vX <= dCUT[\"B\"])\n",
    "            vV1_ISS[mB] = float(dV1[\"B\"])\n",
    "\n",
    "            mBB = (vX > dCUT[\"B\"]) & (vX <= dCUT[\"BB\"])\n",
    "            vV1_ISS[mBB] = float(dV1[\"BB\"])\n",
    "\n",
    "            mBBB = (vX > dCUT[\"BB\"]) & (vX <= dCUT[\"BBB\"])\n",
    "            vV1_ISS[mBBB] = float(dV1[\"BBB\"])\n",
    "\n",
    "            mA = (vX > dCUT[\"BBB\"]) & (vX <= dCUT[\"A\"])\n",
    "            vV1_ISS[mA] = float(dV1[\"A\"])\n",
    "\n",
    "            mAA = (vX > dCUT[\"A\"]) & (vX <= dCUT[\"AA\"])\n",
    "            vV1_ISS[mAA] = float(dV1[\"AA\"])\n",
    "\n",
    "            # Issuer value contribution\n",
    "            vV_PORT += vUNITS[k] * vV1_ISS\n",
    "\n",
    "        # Loss distribution (positive loss = bad)\n",
    "        vLOSS = float(iTOTALMV) - vV_PORT\n",
    "\n",
    "        # Expected value\n",
    "        fEV = float(np.mean(vV_PORT))\n",
    "\n",
    "        # VaR / ES\n",
    "        dOUT = {\"Portfolio\": sPORT, \"Rho\": fRHO, \"Expected Value\": fEV}\n",
    "\n",
    "        # Iterate over confidence levels\n",
    "        for fA in vALPHA:\n",
    "            fVaR = float(np.quantile(vLOSS, fA))\n",
    "            mTAIL = vLOSS >= fVaR\n",
    "            fES = float(np.mean(vLOSS[mTAIL]))\n",
    "\n",
    "            sA = f\"{int(round(fA*1000))/10:.1f}%\"\n",
    "            dOUT[f\"VaR_{sA}\"] = fVaR\n",
    "            dOUT[f\"ES_{sA}\"] = fES\n",
    "\n",
    "        # Store results\n",
    "        vRESULTS.append(\n",
    "            {\n",
    "                \"Portfolio\": dOUT[\"Portfolio\"],\n",
    "                \"Rho\": dOUT[\"Rho\"],\n",
    "                \"Expected Value\": dOUT[\"Expected Value\"],\n",
    "                \"90% VaR\": dOUT[\"VaR_90.0%\"],\n",
    "                \"99.5% VaR\": dOUT[\"VaR_99.5%\"],\n",
    "                \"90% ES\": dOUT[\"ES_90.0%\"],\n",
    "                \"99.5% ES\": dOUT[\"ES_99.5%\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Final table for Question 2\n",
    "dfQ2 = pd.DataFrame(vRESULTS).sort_values([\"Portfolio\", \"Rho\"]).reset_index(drop=True)\n",
    "\n",
    "# Display results for Question 2\n",
    "print(\"Diversified — 100 issuers per rating:\")\n",
    "print(dfQ2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f591cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dfQ2 to LaTeX –––––\n",
    "\n",
    "with open(\"Documentation/Tables/ccsr-a1-results-diversified.tex\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[ht]\\n\")\n",
    "    f.write(\"\\\\centering\\n\")\n",
    "    f.write(\"\\\\caption{Diversified Portfolio Results}\\n\")\n",
    "    f.write(\"\\\\label{tab:results_diversified}\\n\")\n",
    "    f.write(\"\\\\begin{tabular}{lrrrrrrr}\\n\")\n",
    "    f.write(\"\\\\toprule\\n\")\n",
    "    f.write(\"Portfolio & Rho ($\\\\rho$) & Expected Value & $\\\\text{VaR}_{0.90}$ & $\\\\text{VaR}_{0.995}$ & $\\\\text{ES}_{0.90}$ & $\\\\text{ES}_{0.995}$ \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\midrule\\n\")\n",
    "    for _, row in dfQ2.iterrows():\n",
    "        f.write(f\"{row['Portfolio']} & {row['Rho']:.2f} & {row['Expected Value']:.4f} & {row['90% VaR']:.2f} & {row['99.5% VaR']:.2f} & {row['90% ES']:.2f} & {row['99.5% ES']:.2f} \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\bottomrule\\n\")\n",
    "    f.write(\"\\\\end{tabular}\\n\")\n",
    "    f.write(\"\\\\end{table}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e302b744",
   "metadata": {},
   "source": [
    "## **Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a86963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 vs Q2 comparison\n",
      "          Portfolio   Rho  99.5% VaR_Q1_conc  99.5% VaR_Q2_div  \\\n",
      "0  Investment Grade  0.00          27.130707          2.194930   \n",
      "1  Investment Grade  0.33          33.794513         16.966627   \n",
      "2  Investment Grade  0.66          37.496420         31.346841   \n",
      "3  Investment Grade  1.00          49.974574         49.974574   \n",
      "4              Junk  0.00         290.029707         14.295953   \n",
      "5              Junk  0.33         307.409178        137.514946   \n",
      "6              Junk  0.66         370.275806        265.980201   \n",
      "7              Junk  1.00         478.670725        478.670725   \n",
      "\n",
      "   99.5% ES_Q1_conc  99.5% ES_Q2_div  \n",
      "0         56.367254         2.588288  \n",
      "1         56.421773        24.555555  \n",
      "2         72.014173        52.719401  \n",
      "3         85.167830        84.100197  \n",
      "4        305.463794        16.315566  \n",
      "5        377.010625       172.636312  \n",
      "6        445.929820       325.429728  \n",
      "7        478.670725       478.670725  \n"
     ]
    }
   ],
   "source": [
    "# Comparison of Concentrated vs Diversified Portfolio –––––\n",
    "\n",
    "# Comparison table\n",
    "dfCMP = (dfQ1.merge(dfQ2, on=[\"Portfolio\", \"Rho\"], suffixes=(\"_Q1_conc\", \"_Q2_div\")))\n",
    "\n",
    "# Display comparison\n",
    "print(\"Q1 vs Q2 comparison\")\n",
    "print(dfCMP[[\n",
    "    \"Portfolio\",\"Rho\",\n",
    "    \"99.5% VaR_Q1_conc\",\"99.5% VaR_Q2_div\",\n",
    "    \"99.5% ES_Q1_conc\",\"99.5% ES_Q2_div\"\n",
    "]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19774171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comparison to LaTeX –––––\n",
    "\n",
    "with open(\"Documentation/Tables/ccsr-a1-results-comparison.tex\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{table}[ht]\\n\")\n",
    "    f.write(\"\\\\centering\\n\")\n",
    "    f.write(\"\\\\caption{Comparison of Concentrated vs Diversified Portfolio Results}\\n\")\n",
    "    f.write(\"\\\\label{tab:results_comparison}\\n\")\n",
    "    f.write(\"\\\\begin{tabular}{l r r r r r}\\n\")\n",
    "    f.write(\"\\\\toprule\\n\")\n",
    "    # First header row (grouped)\n",
    "    f.write(\" & & \\\\multicolumn{2}{c}{$\\\\text{VaR}_{0.995}$} \"\n",
    "            \"& \\\\multicolumn{2}{c}{$\\\\text{ES}_{0.995}$} \\\\\\\\\\n\")\n",
    "    # Second header row (sub-columns)\n",
    "    f.write(\"Portfolio & Rho ($\\\\rho$) & Concentrated & Diversified & Concentrated & Diversified \\\\\\\\\\n\")\n",
    "    f.write(\"\\\\midrule\\n\")\n",
    "    for _, row in dfCMP.iterrows():\n",
    "        f.write(\n",
    "            f\"{row['Portfolio']} & {row['Rho']:.2f} & \"\n",
    "            f\"{row['99.5% VaR_Q1_conc']:.2f} & {row['99.5% VaR_Q2_div']:.2f} & \"\n",
    "            f\"{row['99.5% ES_Q1_conc']:.2f} & {row['99.5% ES_Q2_div']:.2f} \\\\\\\\\\n\"\n",
    "        )\n",
    "    f.write(\"\\\\bottomrule\\n\")\n",
    "    f.write(\"\\\\end{tabular}\\n\")\n",
    "    f.write(\"\\\\end{table}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d016674",
   "metadata": {},
   "source": [
    "## **Code export**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "238f6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export python code / markdown cells separately –––––\n",
    "\n",
    "# Config –\n",
    "NAME = \"ccsr-a1\"\n",
    "\n",
    "# Import –\n",
    "import nbformat\n",
    "\n",
    "# Load notebook –\n",
    "nb = nbformat.read(f\"{NAME}-script.ipynb\", as_version=4)\n",
    "\n",
    "# Write code cells into one python script –\n",
    "with open(f\"Documentation/{NAME}-script.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == \"code\":\n",
    "            f.write(cell.source.replace(\"–\", \"-\") + \"\\n\\n\")\n",
    "\n",
    "\n",
    "# Collect markdown cells –\n",
    "md_cells = [cell['source'] for cell in nb.cells if cell['cell_type'] == 'markdown']\n",
    "\n",
    "# Write them into one markdown file\n",
    "with open(f\"Documentation/{NAME}-markdown.md\", \"w\") as f:\n",
    "    f.write(\"\\n\\n\".join(md_cells))\n",
    "\n",
    "\n",
    "# Convert markdown to LaTeX using pandoc –\n",
    "# rewrite and run in bash\n",
    "# pandoc Documentation/{NAME}-markdown.md -o Documentation/{NAME}-markdown.tex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
